% !TEX root = ../thesis.tex
%
\chapter{Implementation Details}
\label{sec:implementation}

TODO: TS1 vs TS2
      Implicit greedy schedules with Call vs Fair schedules with cast
      Evaluation Model: JSON parsing -> GenServer -> MessageQueue for inputs -> Evaluation of each Node \dots

Besides the theoretical basics presented in \cref{sec:related} the \gls{tessla} runtime of this thesis is built upon a number of technologies.
To better understand decisions made during the implementation this chapter will give an overview of them and show why they were choosen.

As already mentioned, the implemented runtime itself is independent of the way traces are generated.
Therefore we will not only look at building blocks for the runtime itself but also examine related projects which can be used to obtain traces, which then can be monitored by the runtime.
Because the format of the traces can differ heavily, depending on how and why they were collected, they are not only used to test the runtime but also to determine how it can consume them.

\section{TesslaServer}
\label{sec:implementation:tesslaserver}

The runtime to evaluate specifications is implemented in the programming language Elixir, which itself is built on top of Erlang, BEAM and OTP.
To understand why this plattform was choosen we will look at the Erlang ecosystem in the next section.

\subsection{Erlang and Elixir}
\label{sec:implementation:tesslaserver:erlang_elixir}
BEAM, Actors/Thread, multiplattform (nerves project)
Timing model: reason why events have to carry timestamps in contrast to interweaved monitors
Compare V1 and V2

\subsection{Instrumentation Pass}
\label{sec:implementation:instrumentation}


\subsection{GCC instrument functions}
\subsection{LLVM/clang AST matchers}
