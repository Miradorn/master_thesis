% !TEX root = ../thesis.tex
%
\chapter{Conclusion}
\label{sec:conclusion}

In this chapter we will revisit the work done in the whole thesis and see which parts remain to be done.
In the final section an overview of future work is given, highlighting challenges that can be approached based on the work that is already done.

\section{TesslaServer}

As the evaluation in \Cref{sec:evaluation:runtime_benchmarks,sec:evaluation:runtime_examples} shows the implemented runtime is able to evaluate a variety of specifications in a performant way.
The new architecture for the runtime improved the performance in many ways, especially enabling the evaluation of complex specifications with many input events.
Nonetheless it has to be noted that the runtime at the moment is mainly a proof of concept and isn't tested under real life circumstances or with actual systems.

At the moment there are two drawbacks of the runtime that are based on limitations of the current version of the \gls{tessla} compiler.
The limitations are missing type information and missing output information.

Let's first understand the lack of type information and the impact of the runtime.
The \gls{tessla} compiler is able to infer a lot of type information, therefore making it possible to omit type information from \gls{tessla} specifications.
Many functions in \gls{tessla} are generic over the type they consume or produce.
Recall that each function in \gls{tessla} is generic, since they work either on signals or eventstreams which carry a type themself, e.g. a function can have the output type \lstinline{Events<Int>} or \lstinline{Signal<Boolean>}.
Furthermore a function can be generic not only over the type of the values of its streams but also what kind of stream (signal or eventstream) it consumes or produces.
Also the same function can be defined over different aritys, for example an \emph{add} function could be defined for 2, 3 or any number of arguments (note that \gls{tessla} doesn't support methods with a varying number of arguments, in some languages known as \emph{varargs}, as of now).

This leads to a situation where for example the \emph{delay} function, which delays stream by an amount, has actually three generic types: \lstinline{Events<A>,time -> Events<A>}, \lstinline{Signal<A>,time,A -> Events<a>} and \lstinline{Events<A>, Int -> Events<A>}.
The first and second functions are delaying a stream by a certain time, the second one having a default value as the third argument, and the las function delaying the events on an eventstream by a given amount of steps, meaning the first event will be delayed to the timestamp of the second event.

The compiler is now able to match the signatures of a used function to the correct one and will check if the whole specification is correct with respect to the type system.
The problem is in the output of the compiler which doesn't contain type informations anyomore, meaning that the representation of the first and third \emph{delay} functions are exactly the same and the runtime would have to figure out which type of the function it should actually use.
For the moment two workarounds are present in the runtime and compiler until the type informations are included in the output.

The first workaround is for functions which work with signals and eventstreams and have the same arity.
To make them work without type information they are split into multiple functions, one for each argument that can take either a signal or an eventstream.
For example the two \emph{delay} functions with the same arity are split into a \emph{delayEventsByTime} and a \emph{delayEventsByCount} function.
This moves some responsibility to the user writing a spec since he has to use the right function and can't rely on the compiler to figure out the correct one.
Furthermore this leads to an increased implementation effort for the runtime, since more node types have to implemented.
The second workaround is much simpler: functions which work on streams with generic type of values (e.g. \lstinline{Signal<A>}) will use \emph{Int} as the default type and doesn't support any other types.

The desired solution to the problem is, that the compiler will somehow include the type signature of functions in the output.
The signature could than be used at runtime to dynamically convert the values of events to the matching types.

The lack of output information is easier to understand and solve.
In \gls{tessla} specifications one denotes that a stream is an output stream with the \lstinline{out} keyword.
At the moment the compiler isn't handling this keyword at all and therefore it is missing in the output.
The workaround for now is, that output nodes have to be specified when the runtime is started, therefore a typical invocation of TesslaServer looks like \lstinline[language=bash]{./tessla_server example.spec -o 4:error} where the \emph{o} flag denotes an output, 4 is the id of the node that generates the output stream and \emph{error} is a name that can be chosen by the user.

A last missing functionality we want to highlight is based on the asynchronous nature of the runtime.
Since nodes are independent of each other and share no knowledge, except the one that is explicitly shared by messages, there is no global state that can be used to track if all nodes have finished their computation.
Furthermore there is no shared progres between independent nodes in the new architecture, or in other words each source will be progressed to a different timestamp.

This leads to a problem when the trace actually ends: Think of a specification with two independent sources and a trace which contains events on the stream of the first source upto timestamp \(t_2\) but for the stream of the second stream only to the timestamp \(t_1\) with \(t_1 < t_2\).
When the trace ends the second source will have only progressed to \(t_1\) while the trace implicitly contains the information that there is no event happening on its input stream at any time later than \(t_1\).
This information could lead to new generated events of a child node, e.g. a \emph{timeout} node which could then lead to new output events.

A simple workaround would be to implement a \emph{flush} mechanism, which will send each source node a message that there will be no more input events and therefore they can progress to the maximal timestamp.
With this mechanism all children of sources will then receive the information that their inputs have progressed without generating new events, enabling them to also progress to the maximal time.
The information that all inputs have finished will transitively flow thourgh the whole system and at one point all nodes will have performed their final computation and the system will have generated all possible outputs.

\section{Instrumentation Pass}

In the benchmarks of the instrumentation it is obvious that it adds a lot of overhead, especially when compiler optimizations are turned on or the percentage of instrumented function calls is large.
While the overhead is big, it is stable (see the standard deviation in \Cref{sec:evaluation:instrumentation_benchmark:instr_vs_non_inst}).

For now the instrumentation should be seen as a proof of concept and test tool.
The generated traces should be mostly used to analyse test settings where compiler optimizations are turned off.
When used for timing specifications, the instrumented code can be benchmarked against a non instrumented version of the code and the results can be used to transform the actual timing requirements to corresponding ones for the instrumented code.
This will at least give an approximation of the actual results.
Also it is recommended to write small and specific \gls{tessla} specifications, so that the instrumentations only have to be applied to a small subset of functions.
Obviously it is strongly discouraged to use the instrumented code in any production setting.

Two enhancements could be easliy integrated into the instrumentation pass:
Enabling the logging of more event types, like variable reads or memory allocation, while also including data in the events and introducing a better configuration format to specify what events should be logged.

As explained in \Cref{sec:implementation:instrumentation} the compiler pass is instrumented as a \emph{ModulePass}, enabling the logging of all kinds of events.
While the logging of function calls was sufficient for testing and evaluation purposes this restriction together with the total lack of logging data is an obvious problem for more serious use cases.
The trace format already includes a field for data values and the instrumentation pass has the ability to extract data, e.g. function arguments or return values, from the source code it is transforming.

Also the expansion to more event types shouldn't be too complicated when harnessing the \emph{InstVisitor}\footnote{\url{http://llvm.org/docs/doxygen/html/classllvm_1_1InstVisitor.html}} mechanism.
An \emph{InstVisitor} can be used to abstract the actual iteration over the building blocks of the \gls{ir} of a program, so that the user only has to specify the transformation that should be happening when a specific instruction type is seen.
For example the instrumentation of return statements could use the \emph{visitReturnInst} \gls{api} to handle all return statements and change them to log an event.

In the context of adding more event types to the instrumentation pass the configuration format becomes a problem.
For now a user specifys each function that should be instrumented when calling the pass with an option to the compiler pass like \lstinline{-instrument FUNCTIONNAME}.
This approach obviously doesn't scale when multiple event types are implemented.
Therefore a common configuration format should be specified and the instrumentation pass should read it from a given file.
This approach would also enable the sharing of configuration files between different developers and the versioning of them using version control systems.

\section{Further Work}
\label{sec:conclusion:further_work}

Composition of Transducers/evalEngines
Port to Scala/akka
Different evaluation model: Pull not push
  port to genstage: Concept of backpressure -> Nodes generating events out of nothing
Slicing/parameter


online monitoring -> possible infinite traces

maybe define new functions (read nodes) in the spec itself and not in the runtime? Also recursion in specifications
Optimizations: Bundle up events, throw away unneeded progress events in  bundles
  For some notes only subset of inputs is important for output progress (think if then else)
    -> Some things na be optimized by compiler (literal as cond to ite) others only during evaluation.

More fine grained instrumentation pass config
TODO: Timing model, maybe somehow harness Vector clocks -> wwould  compplicate instrumentation! Also would need support in TeSSLa language.
Configuration file for instrumetnation -> e.g. include conditions

\subsection{Error prevention}
\label{sec:conclusion:further_work:error_prevention}
Ways of sending observations back to the program to recover from or prevent errors

