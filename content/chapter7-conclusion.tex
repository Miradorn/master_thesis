% !TEX root = ../thesis.tex
%
\chapter{Conclusion}
\label{sec:conclusion}

\section{Conclusion for TesslaServer}

note limitations of Type system of compiler and Runtime

Optimizations: Bundle up events, throw away unneeded progress events in  bundles
  For some notes only subset of inputs is important for output progress (think if then else)
    -> Some things na be optimized by compiler (literal as cond to ite) others only during evaluation.

Implement 'end' notification to flush all values.
Total ordering of inputs necessary, relax to per channel. Argue that channels could be split by thread id.

\section{Conclusion for the Instrumentation Pass}
TODO: Timing model, maybe somehow harness Vector clocks -> wwould  compplicate instrumentation! Also would need support in TeSSLa language.
Extract logging to  different thread ->  run on own core, less overhead.
Configuration file for instrumetnation -> e.g. include conditions

In the benchmarks of the instrumentation it is obvious that it adds a lot of overhead, especially when compiler optimizations are turned on or the percentage of instrumented function calls is large.
While the overhead is big, it is stable (see the standard deviation in \Cref{sec:evaluation:instrumentation_benchmark:instr_vs_non_inst}).

For now the instrumentation should be seen as a proof of concept and test tool.
The generated traces should be mostly used for analysing test settings, where compiler optimizations are turned off.
When used for timing specifications, the instrumented code can be benchmarked against a non instrumented version of the code and the results can be used to transform the actual timing requirements to corresponding ones for the instrumented code.
This will at least give an approximation of the actual results.
Also it is recommended to write small and specific \gls{tessla} specifications, so that the instrumentations only have to be applied to a small subset of functions.
Obviously it is strongly discouraged to use the instrumented code in any production setting.

\section{Further Work}
\label{sec:conclusion:further_work}

Composition of Transducers/evalEngines
Port to Scala/akka
Different evaluation model: Pull not push
  port to genstage: Concept of backpressure -> Nodes generating events out of nothing


online monitoring -> possible infinite traces

Architecture is similar to a vm: Tessla specs are code, compiler produces intermediate representation (json), runtime executes Ir.
Therefore: Maybe define new functions (read nodes) in the spec itself and not in the runtime? Also recursion in specifications

\subsection{Error prevention}
\label{sec:conclusion:further_work:error_prevention}
Ways of sending observations back to the program to recover from or prevent errors

