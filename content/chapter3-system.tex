% !TEX root = ../thesis-example.tex
%
\chapter{System}
\label{sec:system}

\section{Definitions}
\label{sec:system:defs}

There are three Types of Events: Input, Output and Internal.

Let \(E\) be the Set of valid input events (E for external) and \(e \in E\), where each event carries a value, a timestamp and the
channel it is perceived on (e.g.\ a function call of a specific function).
Further let \(O\) be the Set of valid output events and \(o \in O\), which have the same properties than input events.

Internal events are only used by the asynchronous system: Let the Set of valid internal events be \(N\).
Internal events also carry a value and a timestamp, but their channel is implicitly given by the node that produces the event.

% \cleanchapterquote{Innovation distinguishes between a leader and a follower.}{Steve Jobs}{(CEO Apple Inc.)}
\section{Semantics of TeSSLa functions}
\label{sec:system:semantics_tessla_functions}
Think of semantics of thinks like add, mrv, etc.
Can these be defined independent of async/synchronous or for each.
For synchronous they are partly defined in the TeSSLa spec

\section{Semantics of an ideal, synchronous evaluation Engine}
\label{sec:system:semantics_ideal}
An ideal implementation \(I\) for a specification \(T\) is one that consumes an input event \(e_x\) and immediately emits
appropriate output Events \(o_{1,1}, o_{1,2}, \dots , o_{1,x}\) with \(x \in \mathbb{N}_{\ge0}\) and changes it's internal
state \(S\) to save the fact, that the event \(e_x\) was received and optionally other properties generated by the
evaluation of the spec that are needed by later computations.

Therefore it's behaviour for a single input can be described by two functions:
\begin{align*}
  \Phi&: S \times E \rightarrow S \\
  \Theta&: S \times E \rightarrow O^*
\end{align*}

The behaviour for multiple inputs is the composition of the functions.

The semantics for the implementation \(I\) for a Stream of input events from \(E^*\) is given by the output Stream
from \(O^*\) that is generated by the formulas.

The processing of a series of 3 input events can be visualized like shown in Figure~\ref{fig:chap3:sec_sync:form_sync_processing}.

\begin{figure}
  \begin{flalign*}
    &\text{Timestamp:}  && t_0      &&t_1\                          &&t_2                        &&t_3 &\\
    &\text{Input:}      &&          &&e_1\                          &&e_2                        &&e_3 &\\
    &\text{State:}      && I_0      &&I_1\                          &&I_2                        &&I_3 &\\
    &\text{Outputs:}    &&          &&(o_{1,1}, \dots, o_{1,x})     &&(o_{2,1}, \dots, o_{2,y})  &&(o_{3,1}, \dots, o_{3,z}) &
  \end{flalign*}
  \caption{Example computation of 3 Inputs by an ideal implementation}
\label{fig:chap3:sec_sync:form_sync_processing}
\end{figure}

\section{Semantics of an asynchronous evaluation Engine}
\label{sec:system:semantics_async}

An asynchronous implementation \(A\) for a specification \(T\) has more complex characteristics:
It's state is defined by the product of the States of it's nodes, where each node represents a primitive operation in
the specification and the nodes are organized as a DAG.%TODO glossary
The output is specified by the concatination of outputs of the nodes that are marked as output nodes in the specification.

In contrast to \(I\) the asynchronous implementation takes multiple steps to produce an output from an input.
During a step multiple things can happen at once:
\begin{itemize}
  \item A new, external input Event can be consumed by a source in the DAG, which generates an internal event that is propagated to it's children
  \item An internal Node which has at least one new input buffered on its input queue can perform
    it's computation, generate a new internal event, which is propagated to the children of that node, which therefore could compute in the next step.
  \item An output node, which has at least one new input buffered on its input queue, can produce a new output.
\end{itemize}

To reason about the steps $A$ takes while performing a computation, we have to define a schedule of the computations of the nodes.
This schedule has to be fair, otherwise it's possible that no output would ever be created, because the output nodes will be never scheduled.
Such a schedule is given by the following algorithm:

\begin{itemize}
  \item Number the nodes in reversed topological order
  \item schedule the node with the lowest number that has an input event buffered
\end{itemize}

As shown in Section~\ref{TODO} this is a fair schedule.

Figure~\ref{fig:async_dag} shows two DAG representations of an asynchronous system where the Nodes A to D are labeled
in a reversed topological order and o and u represents the output channels with that name.
The left system is in it's initial State and an input event \(\langle e_1,t_1\rangle\) is ready to be consumed.
When a node is chosen to compute by the scheduler, only node A is ready, therefore it is scheduled.
The right system is the representation of the next step: Node A has consumed the external event and produced an internal event
\(\langle n_A,t_1\rangle\) which is proppagated to all it's children, Node B and C.
In the next step Node B would be scheduled, because it has the lowest number, a different reversed topological order could habe
labeled B with 3, C with 2 and D with 1, then D would have been scheduled instead of B.
After B was scheduled, it would have produced the internal Event \(\langle n_B,t_1\rangle\) which would then be emitted as the output event
\(\langle o_1,t_1 \rangle\).
Therefore the trace of consumed external and produced internal and output events by the system with this specific schedule could be visualized as:
\[
  \langle I_1,t_1 \rangle \langle n_{A1},t_1 \rangle \langle n_{B1},t_1 \rangle \langle o_1,t_1 \rangle \langle n_{C1},t_1 \rangle \langle n_{D1},t_1 \rangle \langle u_1,t_1 \rangle
\]
If there were more than one input events, at this point Node A would be scheduled again, consume the next external event and the following nodes would be scheduled in the same order as before,
extending the trace in a obious way.

\begin{figure}
  \begin{tikzpicture}
    [pre/.style={<-,shorten <=1pt,>=stealth,semithick}]

    \node (E) {\(<e_1,t_1>\)};
    \node [shape=circle,draw=black] (A) [label=right:4, below=of E] {A}
      edge [pre] (E);
    \node [shape=circle,draw=black] (B) [label=right:1, below left=of A] {B}
      edge [pre] (A);
    \node [shape=circle,draw=black] (C) [label=right:3, below right=of A] {C}
      edge [pre] (A);
    \node [shape=circle,draw=black] (D) [label=right:2, below right=of C] {D}
      edge [pre] (C);
    \node (o) [below=of B] {o} edge [pre] (B);
    \node (u) [below=of D] {u} edge [pre] (D);
  \end{tikzpicture}
  \begin{tikzpicture}
    [pre/.style={<-,shorten <=1pt,>=stealth,semithick}]

    \node [shape=circle,draw=black] (A) [label=right:4] {A};
    \node [shape=circle,draw=black] (B) [label=right:1, below left=of A] {B}
      edge [pre] node[align=left,left,pos=0.6] {\(\langle n_{A1},t_1\rangle\)} (A);
    \node [shape=circle,draw=black] (C) [label=right:3, below right=of A] {C}
      edge [pre] node[align=right,right,pos=0.6] {\(\langle n_{A1},t_1\rangle\)} (A);
    \node [shape=circle,draw=black] (D) [label=right:2, below right=of C] {D}
      edge [pre] (C);
    \node (o) [below=of B] {o} edge [pre] (B);
    \node (u) [below=of D] {u} edge [pre] (D);
  \end{tikzpicture}
  \caption{Visualization of a simple asynchronous system with a reversed topological order.}
\label{fig:async_dag}
\end{figure}

\section{Equality of Semantics for a topological schedule}
\label{sec:sysyem:equal_semantics_topological}

\(A\) and \(S\) are considered equal if for a Series of input Events they produce the same output Events, or stated otherwise:
The equality is defined only over the traces they consume and produce.
\(A\) won't emit the outputs in the right order, but because each events carry the timestamp they were created at,
the relationship between consumed input events and produced outputs based on that event can be restored.
The following paragraphs will give a more precise notion of the equality between the systems.

To proof the equality of both systems we have to proof the equality of the states \(A\) will take, while producing the
outputs, to the States \(I\) takes.
Let \(e_1, e_2, \dots, e_x\) be the input events both implementations receive.
The State of \(I\) will change every time a new input is received and will produce all outputs that could be computed.

Due to the asynchronous nature of \(A\) there is no direct mapping from the states of \(I\) to the states of \(A\), because
\(A\) will compute outputs in a non deterministic order.
Therefore the equality has to be shown inductive over the possible States \(A\) could reach while computing the outputs.

Let's first reason about the easy case, were only one external event is received:
In this case \(I\) has only two states, \(I_0,\ I_1\) and will only produces outputs once: \(o_{1,1}, \dots, o_{1,x}\).
\(A\) will walk through multiple states, bound by the number of functions in the specification it's implementing.
Because the specification is a DAG, especially has no circles, eventually \(A\) has to finish it's computation, let the
number of steps be \(k\).
Let \(h_{\min}\) be the minimal height of the DAG (the height of the leave with the fewest steps to the Source).
The first output can only be created after \(h_{\min}\) steps and after step \(k\) all outputs have to be created, so that
\(o_{1,1}, \dots, o_{1,x}\) were emitted.
Let the States of \(A\) during the computation be \(A_{0}, A_{1,0}, A_{1,1}, \dots, A_{1,k}\) where \(A_0\) is the initial state.
When taking the first step and \(A_{1,0}\) is reached, the event \(e_1\) is consumed and no other node can compute.
Note that there is no alternative to this bahivour, because there were no prior events and therefore no internal Node
has an event to process on it's input queue, therefore the Source consuming the external event is the only node that can,
and therefore must, compute anything.
Afterwards all Nodes that are direct children of the source that consumed the external event will have one input event buffered and
are able to perform their computation in the next step.
At least until step \(h_{\min}\) every step one or more Nodes, that are no outputs, will perform a computation, therefore
pushing internal events closer to the output nodes.
Somewhere between step \(h_{\min}\) and \(k\) all internal events will reach an output node and produce an output.

A more complex case is when multiple events are received.

Because the scheduling of nodes of \(A\) is based on the reversed topological order, \(A\) will only consume one new external event and then will schedule internal nodes until all
internal events have reached an output node, only than the next input will be consumed by a source node.
\(I\) will step through a series of States \(I_0, I_1, \dots, I_x\), A on the other hand will step through a Series of
states for each state that \(I\) takes: \(A_0,A_{1,0},A_{1,1},\dots,A_{1,j1},A_{2,0}, \dots,A_{x,j2}\) and generate internal events along those steps.
Based on this behaviour lets define when a State of \(A\) is equal to one of \(I\):
The first states \(A_0\) and \(I_0\) are always assumed to be equal, because no output can be observed and therefore one
can't observe a difference.
A State \(A_{i,j}\) with \(j > 0\) is called equal to a State \(I_{i}\) iff:
\begin{itemize}
  \item The previous state \(A_{i,j-1}\) was equal to \(I_{i}\)
  \item and either
    \begin{itemize}
      \item No new output was generated at state \(A_{i,j}\)
      \item or if a new output \(o\) is created it is equal to one of the outputs of \(I_{i}\) that wasn't generated before
    \end{itemize}
\end{itemize}

A State \(A_{i,0}\) is called equal to a state \(I_{i}\) iff
\begin{itemize}
  \item The previous state \(A_{i-1,x}\) was equal to \(I_{i-1}\)
  \item the input \(e_i\) was consumed at the step
  \item and the States \(A_{i-1,0}\) to \(A{i-1,x}\) together produced the same output like \(I_{i-1}\)
\end{itemize}

Naively speaking the System \(A\) moves through states \(A_{i,0},\dots,A_{i,x}\) while it produces the same outputs as \(I\)
produced when it reached state \(I_i\), and as soon as the last output was produced consumes a new event and thereby takes
state \(A_{i+1,0}\).

Based on this, a series of states \(\vec{A}\) is called equal to a series of States \(\vec{I}\) if each state in \(\vec{A}\)
is equal to a state in \(\vec{I}\).
The System \(A\) is equal to the system \(I\) in regard to a series of inputs \(\vec{e}\) iff all possible series of
states it could take to process \(\vec{e}\) are equal to \(\vec{I}\).

\section{Semantics between different schedules for an asynchronous system}
\label{sec:semantics_schedules}

% \begin{figure}[htb]
%     \includegraphics[width=\textwidth]{gfx/Clean-Thesis-Figure}
%     \caption{Figure example: \textit{(a)} example part one, \textit{(c)} example part two; \textit{(c)} example part three}
%     \label{fig:system:example1}
% \end{figure}

% \begin{figure}[htb]
%     \includegraphics[width=\textwidth]{gfx w/Clean-Thesis-Figure}
%     \caption{Another Figure example: \textit{(a)} example part one, \textit{(c)} example part two; \textit{(c)} example part three}
%     \label{fig:system:example2}
% \end{figure}

